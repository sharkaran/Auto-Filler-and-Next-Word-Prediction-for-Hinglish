{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# for output text wrap\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "aOjBWHcyEEiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "50717dd6-c93f-493b-db6c-5eae0cc17d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging Text Files"
      ],
      "metadata": {
        "id": "Sa4p5J3F_jtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "big_data = \"\"\n",
        "\n",
        "\n",
        "directory = 'archive'\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    if os.path.isfile(f):\n",
        "        with open(f, 'r') as file:\n",
        "            try:\n",
        "                text = file.read()\n",
        "                big_data = big_data + \" \" + text\n",
        "            except:\n",
        "                print(f)\n",
        "with open('big_data.txt', 'w') as fw:\n",
        "    fw.write(big_data)"
      ],
      "metadata": {
        "id": "KYyGoPSWpmjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "oufpJM54_wxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ySmj5ro3xM3T",
        "outputId": "7b48f6b6-3843-4b4e-9efc-5387e4ae0de5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# file_path = \"The_dataset.txt\"\n",
        "file_path = \"big_data.txt\"\n",
        "with open(file_path, 'r') as file:\n",
        "  text = file.read()\n",
        "text = text.lower()\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "XukzWvQayyKs",
        "outputId": "0585cdcc-c3c3-419f-9a0b-be6ef85d404c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Sentences"
      ],
      "metadata": {
        "id": "1S_fs_ZC_5l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(text)\n",
        "# print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G67H58hhzjgj",
        "outputId": "117d115a-b3c7-4341-c399-a8d3ba1b1670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Tokenizer which removes punctuations"
      ],
      "metadata": {
        "id": "LXN3BiuuAB1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
      ],
      "metadata": {
        "id": "_-OUJb7g0FYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a31254d1-e32f-4964-b107-4c56d933df2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Vocabulary/ Unigram Counts"
      ],
      "metadata": {
        "id": "mmxUhACa__nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = defaultdict(int)\n",
        "def getVocab():\n",
        "  words = tokenizer.tokenize(text)\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      vocab[word] += 1\n",
        "    else:\n",
        "      vocab[word] = 1\n",
        "getVocab()\n",
        "# print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AwoeON762sW8",
        "outputId": "ab64624b-8b7f-495b-bd07-7ac67cb03208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Bigram Counts"
      ],
      "metadata": {
        "id": "85UmevH9AQv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts = defaultdict(int)\n",
        "def getBigramCounts():\n",
        "  for sentence in sentences:\n",
        "    bigrams = nltk.ngrams(tokenizer.tokenize(sentence), 2)\n",
        "    for bigram in bigrams:\n",
        "      if \" \".join(bigram) in bigram_counts:\n",
        "        bigram_counts[\" \".join(bigram)] += 1\n",
        "      else:\n",
        "        bigram_counts[\" \".join(bigram)] = 1\n",
        "getBigramCounts()\n",
        "# print(bigram_counts)"
      ],
      "metadata": {
        "id": "R1lAp6mW22_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "41defe49-0c4b-421c-b80e-685cf52d2ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Trigram Counts"
      ],
      "metadata": {
        "id": "L4rbQca_AVaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_counts = defaultdict(int)\n",
        "def getTrigramCounts():\n",
        "  for sentence in sentences:\n",
        "    trigrams = nltk.ngrams(tokenizer.tokenize(sentence), 3)\n",
        "    for trigram in trigrams:\n",
        "      if \" \".join(trigram) in trigram_counts:\n",
        "        trigram_counts[\" \".join(trigram)] += 1\n",
        "      else:\n",
        "        trigram_counts[\" \".join(trigram)] = 1\n",
        "getTrigramCounts()\n",
        "# print(trigram_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iVPgngeh5kJW",
        "outputId": "ba4268cb-bafa-4c9d-8244-a9b925d1c7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Quadgram Counts"
      ],
      "metadata": {
        "id": "ljK99fzOAYJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quadgram_counts = defaultdict(int)\n",
        "def getQuadgramCounts():\n",
        "  for sentence in sentences:\n",
        "    quadgrams = nltk.ngrams(tokenizer.tokenize(sentence), 4)\n",
        "    for quadgram in quadgrams:\n",
        "      if \" \".join(quadgram) in quadgram_counts:\n",
        "        quadgram_counts[\" \".join(quadgram)] += 1\n",
        "      else:\n",
        "        quadgram_counts[\" \".join(quadgram)] = 1\n",
        "getQuadgramCounts()\n",
        "# print(quadgram_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vPpngZzs6TK4",
        "outputId": "f61c86b2-1c21-4ef2-c744-edce07a6b8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Bigram Probabilities"
      ],
      "metadata": {
        "id": "pn3PHAPkAbIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_prob = defaultdict(int)\n",
        "def findBigramProb():\n",
        "  V = len(vocab)\n",
        "  for bigram in bigram_counts:\n",
        "    unigram = bigram.split()[0]\n",
        "    prob = (bigram_counts[bigram] + 1)/(vocab[unigram] + V)\n",
        "    if unigram not in bigram_prob:\n",
        "      bigram_prob[unigram] = []\n",
        "    bigram_prob[unigram].append([prob, bigram.split()[-1]])\n",
        "findBigramProb()\n",
        "# print(bigram_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uQbWIk9Q6oF7",
        "outputId": "dbf098c2-1edc-4fe3-8906-551ac77cfb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Trigram Probabilities"
      ],
      "metadata": {
        "id": "oN5080g1AeSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_prob = defaultdict(int)\n",
        "def findTrigramProb():\n",
        "  V = len(vocab)\n",
        "  for trigram in trigram_counts:\n",
        "    bigram = \" \".join(trigram.split()[:2])\n",
        "    prob = (trigram_counts[trigram] + 1)/(bigram_counts[bigram] + V)\n",
        "    if bigram not in trigram_prob:\n",
        "      trigram_prob[bigram] = []\n",
        "    trigram_prob[bigram].append([prob, trigram.split()[-1]])\n",
        "findTrigramProb()\n",
        "# print(trigram_prob)"
      ],
      "metadata": {
        "id": "g8xVVgeo86U4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "516621b3-182d-4510-cec5-b80c3e40faf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Quadgram Probabilities"
      ],
      "metadata": {
        "id": "3Ff9m2ExAgcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quadgram_prob = defaultdict(int)\n",
        "def findQuadgramProb():\n",
        "  V = len(vocab)\n",
        "  for quadgram in quadgram_counts:\n",
        "    trigram = \" \".join(quadgram.split()[:3])\n",
        "\n",
        "    prob = (quadgram_counts[quadgram] + 1)/(trigram_counts[trigram] + V)\n",
        "    if trigram not in quadgram_prob:\n",
        "      quadgram_prob[trigram] = []\n",
        "    quadgram_prob[trigram].append([prob, quadgram.split()[-1]])\n",
        "findQuadgramProb()\n",
        "# print(quadgram_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7wdnRuQc_5Xh",
        "outputId": "8d0d09e5-a4cc-43a3-a7ec-1362c6461c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting words based on probabilities"
      ],
      "metadata": {
        "id": "-_hVOBaYAlrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sortProbDicts():\n",
        "  for key in bigram_prob:\n",
        "    if len(bigram_prob[key]) > 1:\n",
        "      bigram_prob[key] = sorted(bigram_prob[key], reverse=True)\n",
        "  \n",
        "  for key in trigram_prob:\n",
        "    if len(trigram_prob[key]) > 1:\n",
        "      trigram_prob[key] = sorted(trigram_prob[key], reverse=True)\n",
        "  \n",
        "  for key in quadgram_prob:\n",
        "    if len(quadgram_prob[key]) > 1:\n",
        "      quadgram_prob[key] = sorted(quadgram_prob[key], reverse=True)\n",
        "\n",
        "sortProbDicts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6xPQPtTnLqWB",
        "outputId": "29a57953-8761-4c39-dde8-bba84423c3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting possible word choices from on probability dicts"
      ],
      "metadata": {
        "id": "24C6akp3AyuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getWordChoices(sentence):\n",
        "  choices = []\n",
        "  tokens = tokenizer.tokenize(sentence.lower())\n",
        "  if tokens[-1] in bigram_prob:\n",
        "    # print(tokens[-1], bigram_prob[tokens[-1]])\n",
        "    choices += bigram_prob[tokens[-1]]\n",
        "\n",
        "  # print(tokens[-2:])\n",
        "  if \" \".join(tokens[-2:]) in trigram_prob:\n",
        "    # print(\" \".join(tokens[-2:]), trigram_prob[\" \".join(tokens[-2:])])\n",
        "    choices += trigram_prob[\" \".join(tokens[-2:])]\n",
        "\n",
        "  if \" \".join(tokens[-3:]) in quadgram_prob:\n",
        "    # print(\" \".join(tokens[-3:]), quadgram_prob[\" \".join(tokens[-3:])])\n",
        "    choices += quadgram_prob[\" \".join(tokens[-3:])]\n",
        "\n",
        "  return choices\n",
        "\n",
        "# getWordChoices('But ek institution me 3 account hi open kar sakte hai')"
      ],
      "metadata": {
        "id": "QEdFYYvwApMS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1f860fe5-6af6-4000-b3e8-eaac1b74c556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing module for finding word similarities"
      ],
      "metadata": {
        "id": "cU6GORkXBNL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jaro-winkler\n",
        "# !pip install jaro\n",
        "import jaro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Dp2fV3hS0ObB",
        "outputId": "88cb2dad-6187-4b29-af32-fa91864db385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaro-winkler\n",
            "  Downloading jaro_winkler-2.0.3-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: jaro-winkler\n",
            "Successfully installed jaro-winkler-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions"
      ],
      "metadata": {
        "id": "y5GLbdggBTYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def doPredictions(sentence):\n",
        "  end_word = None\n",
        "  incomplete = False\n",
        "  # if word is still being type\n",
        "  # removing last word and getting choices wrt to second last word\n",
        "  if sentence[-1] != \" \":\n",
        "    end_word = sentence.split()[-1]\n",
        "    incomplete = True\n",
        "    sentence = \" \".join(sentence.split()[:-1])\n",
        "\n",
        "  choices = {word[1] for word in getWordChoices(sentence)}\n",
        "  predictions = []\n",
        "\n",
        "  V = len(vocab)\n",
        "  num_words = sum(vocab.values())\n",
        "\n",
        "  # merging choices with all possible words from our training corpus\n",
        "  if incomplete:\n",
        "    choices = set(choices.union(vocab.keys()))\n",
        "\n",
        "  for word in choices:\n",
        "    key = sentence + word\n",
        "    quad_token = \" \".join(key.split()[-4:])\n",
        "\n",
        "    # adding the quadgram, trigram, bigram and unigram probabilities to get overall probability\n",
        "    prob = (\n",
        "        (quadgram_counts[quad_token] + 1)/ (trigram_counts[\" \".join(quad_token.split()[-3:])] + V) + \n",
        "        (trigram_counts[\" \".join(quad_token.split()[-3:])] + 1)/ (bigram_counts[\" \".join(quad_token.split()[-2:])] + V) +\n",
        "        (bigram_counts[\" \".join(quad_token.split()[-2:])] + 1)/ (vocab[word] + V) + \n",
        "        (vocab[word] + 1)/ (num_words + V)\n",
        "    )\n",
        "\n",
        "    # adding similarity if sentence is incomplete\n",
        "    if incomplete:\n",
        "      similarity = jaro.jaro_winkler_metric(end_word, word)\n",
        "      predictions.append([similarity, prob, word])\n",
        "    else:\n",
        "      predictions.append([prob, word])\n",
        "\n",
        "  # sorts based on similarity (if sentence is incomplete) and then on probability\n",
        "  predictions = sorted(predictions, reverse=True)\n",
        "  best_preds = [pred[-1] for pred in predictions[:4]]\n",
        "  return best_preds\n",
        "\n",
        "sentence = 'But ek institution me teen account hi open kar sakte hai'\n",
        "print(doPredictions('But ek institution me teen acc'))\n",
        "print(doPredictions('But ek institution me teen acco'))\n",
        "print(doPredictions('But ek institution me teen accou'))\n",
        "print(doPredictions('But ek institution me teen account'))\n",
        "print(doPredictions('But ek institution me teen account '))\n",
        "print(doPredictions('But ek institution me teen account open'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "1K7Njw1k07QJ",
        "outputId": "84d35fdc-7b7e-48d6-b9a5-09faf73cd191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ac', 'accha', 'acchi', 'access']\n",
            "['accout', 'account', 'accounts', 'according']\n",
            "['accout', 'account', 'accounts', 'according']\n",
            "['account', 'accounts', 'accout', 'accent']\n",
            "['hai', 'ke', 'aur', 'se']\n",
            "['open', 'opener', 'pen', 'opening']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export dictionaries as json files for api"
      ],
      "metadata": {
        "id": "6tkouRYnBYQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"bigram_counts.json\",'w') as f:\n",
        "  json.dump(bigram_counts, f)\n",
        "with open(\"trigram_counts.json\", 'w') as f:\n",
        "  json.dump(trigram_counts, f)\n",
        "with open(\"quadgram_counts.json\", 'w') as f:\n",
        "  json.dump(quadgram_counts, f)\n",
        "with open('bigram_prob.json', 'w') as f:\n",
        "  json.dump(bigram_prob, f)\n",
        "with open('trigram_prob.json', 'w') as f:\n",
        "  json.dump(trigram_prob, f)\n",
        "with open('quadgram_prob.json', 'w') as f:\n",
        "  json.dump(quadgram_prob, f)\n",
        "with open(\"vocab.json\", 'w') as f:\n",
        "  json.dump(vocab, f)"
      ],
      "metadata": {
        "id": "yxMLelvr1UH8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "453007de-9479-46d3-dc4e-10d7cb0f77f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}